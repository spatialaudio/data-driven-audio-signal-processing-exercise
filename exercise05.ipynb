{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "489c7bcd-d5b9-4a10-beb9-e58120f4758b",
   "metadata": {},
   "source": [
    "Sascha Spors,\n",
    "Professorship Signal Theory and Digital Signal Processing,\n",
    "Institute of Communications Engineering (INT),\n",
    "Faculty of Computer Science and Electrical Engineering (IEF),\n",
    "University of Rostock,\n",
    "Germany\n",
    "\n",
    "# Data Driven Audio Signal Processing - A Tutorial with Computational Examples\n",
    "\n",
    "Winter Semester 2021/22 (Master Course #24512)\n",
    "\n",
    "- lecture: https://github.com/spatialaudio/data-driven-audio-signal-processing-lecture\n",
    "- tutorial: https://github.com/spatialaudio/data-driven-audio-signal-processing-exercise\n",
    "\n",
    "Feel free to contact lecturer frank.schultz@uni-rostock.de"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201797c2-3cc5-4cce-b1b9-684286f3b759",
   "metadata": {},
   "source": [
    "# Exercise 5: SVD Matrix on Multitrack Audio \n",
    "\n",
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7c76a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pyloudnorm as pyln\n",
    "import shutil\n",
    "from scipy.io import wavfile\n",
    "from numpy.linalg import cond, matrix_rank\n",
    "from scipy.linalg import svd, norm, diagsvd, inv, pinv, null_space\n",
    "\n",
    "# some 'global' variables that should be appear here at top for convenience\n",
    "target_lufs = -32\n",
    "flag_channel = 'Mono'  # 'Left', 'Right' or 'Mono'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e22fb2",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "The notebook gains most fun, if we have multitrack audio to work with, ideally on our own computer, even more ideally we have some own recorded music ;-)\n",
    "\n",
    "We can get some nice multitrack audio material from [https://www.cambridge-mt.com/ms/mtk/](https://www.cambridge-mt.com/ms/mtk/) .\n",
    "\n",
    "This data base supports Mike Senior's 2nd edition of the book \"[The Mixing Secrets For The Small Studio](https://cambridge-mt.com/ms/main/)\".\n",
    "\n",
    "The data base is provided for educational purpose and we will use it precisely this way...maybe in slightly different mixing approach than initially intended, but we will doing a mixing job here...using the SVD.\n",
    "\n",
    "So, if we need some multitrack material, we can download one of the zip files. Below we use 4 examples that worked out very illustratively.\n",
    "\n",
    "To create a matrix where the columns represent the multitrack files (either the left or right channel or summed to mono) we need equal length wav files to work with the code below (I was too lazy to program this nicely).\n",
    "\n",
    "A reasonable workflow is to use a digital audio workstaion (DAW) software, such as [Reaper](https://www.reaper.fm/purchase.php) (please support these guys, non-commercial license is very cheap).\n",
    "\n",
    "In Reaper we would do:\n",
    "- grabbing all multitrack files from a certain zip into an empty project\n",
    "- making them separate tracks\n",
    "- choose an appropriate time selection\n",
    "- do some simple level mixing accroding to actual taste\n",
    "- selecting all tracks\n",
    "- open the `render to file` dialog\n",
    "    - choose Source: `Selected tracks (stems)`\n",
    "    - choose Bounds: `Time selection`\n",
    "    - Directory: create a `multi-track` folder as subfolder where the raw wav files are stored\n",
    "    - File name: `multi-track`\n",
    "    - make sure that original sampling rate is used\n",
    "    - Format: `Wav`\n",
    "    - WAV bit depth: `32 Bit FP` (uses more storage, but then we don't need to pay attention to numbers larger/smaller than 1 if some mixing was performed)\n",
    "    - check `Dry Run (no output`)\n",
    "    - if this simulated rendering comes with the expected channels into the expected number of files with naming convenntion `multi_track-xxx.wav`\n",
    "    - we are ready to render using `Render xxx files``\n",
    "- maybe it's a good idea to save this project for further reference, such as checking what different mixes do to the SVD data...\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781e056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose one of the nice multitrack projects:\n",
    "\n",
    "path = 'audio_ex05/cfx_Mathematician_Full/'\n",
    "# c:fx, 'Mathematician', https://soundcloud.com/c-fx\n",
    "# multitrack for educational use only:\n",
    "# https://mtkdata.cambridgemusictechnology.co.uk/MTK005/cfx_Mathematician.zip\n",
    "\n",
    "path = 'audio_ex05/MaurizioPagnuttiSextet_AllTheGinIsGone/'\n",
    "# Maurizio Pagnutti Sextet, 'All The Gin Is Gone', https://www.artesuono.it/album.aspx?id=76&p=0\n",
    "# for educational use only:\n",
    "# https://multitracks.cambridge-mt.com/MaurizioPagnuttiSextet_AllTheGinIsGone.zip\n",
    "\n",
    "path = 'audio_ex05/cryonicPAX_Excessive/'\n",
    "# cryonicPAX, 'Excessive'\n",
    "# multitrack for educational use only:\n",
    "# https://mtkdata.cambridgemusictechnology.co.uk/MTK015/cryonicPAX_Excessive.zip\n",
    "\n",
    "path = 'audio_ex05/Fin_Echoes/'\n",
    "# FIN, 'Echoes'\n",
    "# multitrack for educational use only:\n",
    "# https://multitracks.cambridge-mt.com/Fin_Echoes.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba965fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up path names\n",
    "pathr = path + 'multi_track/'\n",
    "pathu = path + 'left_singular_vectors/'\n",
    "patha = path + 'reduced_rank_mixdown/'\n",
    "\n",
    "# clear/del path and re-create new to start fresh\n",
    "try:\n",
    "    shutil.rmtree(pathu)\n",
    "except OSError as e:\n",
    "    print(\"Error: %s : %s\" % (pathu, e.strerror))\n",
    "os.mkdir(pathu)\n",
    "try:\n",
    "    shutil.rmtree(patha)\n",
    "except OSError as e:\n",
    "    print(\"Error: %s : %s\" % (pathu, e.strerror))\n",
    "os.mkdir(patha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ae1832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in multitrack wavs and store in a matrix A\n",
    "\n",
    "files = sorted(os.listdir(pathr))\n",
    "print(files)\n",
    "flag_conc = True\n",
    "\n",
    "for i in files:\n",
    "    if i[-4:] == '.wav':  # consider only multi_track-xxx.wav\n",
    "        if i[0:12] == 'multi_track-':\n",
    "            fs, tmp = wavfile.read(pathr+i)\n",
    "            if flag_channel == 'Mono':  # we assume that the files are stereo\n",
    "                # make mono and (xxx, 1) dimension\n",
    "                x = np.expand_dims((tmp[:, 0] + tmp[:, 1]) / 2, 1)\n",
    "            elif flag_channel == 'Left':\n",
    "                # take left channel and (xxx, 1) dimension\n",
    "                x = np.expand_dims(tmp[:, 0], 1)\n",
    "            elif flag_channel == 'Right':\n",
    "                # take right channel and (xxx, 1) dimension\n",
    "                x = np.expand_dims(tmp[:, 1], 1)\n",
    "            else:\n",
    "                print('!!! check flag_channel !!!')\n",
    "                break\n",
    "            print(i, x.shape, x.dtype)\n",
    "            # non-elegant way to stack all stems (single channel tracks) into matrix\n",
    "            if flag_conc:\n",
    "                A, flag_conc = x, False\n",
    "            else:\n",
    "                A = np.concatenate((A, x), axis=1)\n",
    "# since we know sampling frequency (assuming that all multitracks have same),\n",
    "# we can instantiate a lufs meter later to be used\n",
    "lufs_meter = pyln.Meter(fs)\n",
    "\n",
    "print('\\nmulti track matrix A', A.shape, A.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce98c398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD of A and some checks\n",
    "\n",
    "[U, s, Vh] = svd(A, full_matrices=False)\n",
    "print('U shape: ', U.shape)\n",
    "print('Vh shape: ', Vh.shape)\n",
    "print('no of sing vals:', s.size)\n",
    "print('sing vals: ', s)\n",
    "print('condition number: ', cond(A), s[0] / s[-1])\n",
    "\n",
    "print(norm(U @ np.diag(s) @ Vh - A, 'fro'))\n",
    "print(norm(U @ np.diag(s) @ Vh - A, 2))\n",
    "print(norm(U @ np.diag(s) @ Vh - A, 'nuc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f169e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply sing vals to the column space -> we plot the time signals\n",
    "# according to their sing vals strength\n",
    "Us = U  @ np.diag(s)\n",
    "N = Us.shape[0]\n",
    "t = np.arange(N) / fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea31549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot column space signals, i.e. left singular vecs weighted with sing vals\n",
    "# create wav files of these signals to listen to (loudness normalization using BS1770 for convenience)\n",
    "\n",
    "# the above handling indicates:\n",
    "# - relative weighting of the signals in terms of sing vals can be seen in the plots\n",
    "# - listening to the quality of the sing vector signals comes with same loudness\n",
    "\n",
    "nr = 3  # if we have more than 18 tracks we should\n",
    "nc = 6  # choose other nr, nc to fit into suplot\n",
    "plt.figure\n",
    "fig, axs = plt.subplots(nr, nc, figsize=(16, 10))\n",
    "cnt = 0\n",
    "for r in range(nr):\n",
    "    for c in range(nc):\n",
    "        axs[r, c].plot(t, Us[:, cnt])\n",
    "        axs[r, c].set_ylim(-1.5, 1.5)\n",
    "        # we start plotiing/wav writing with index 1\n",
    "        # in order to match rank 1...R wavfiles\n",
    "        axs[r, c].set_title(\n",
    "            r'$\\sigma$={0:3.2f} $\\cdot$ U[{1:d}]'.format(s[cnt], cnt+1))\n",
    "\n",
    "        lufs = lufs_meter.integrated_loudness(Us[:, cnt])  # calc 1770 loudness\n",
    "        tmp = Us[:, cnt] * 10**((target_lufs - lufs) /\n",
    "                                20)  # adapt to target_lufs\n",
    "        if np.max(np.abs(tmp)) > 1.:  # clipping might occur\n",
    "            print('!!! wav file clipping !!!, decrease target_lufs to:')\n",
    "            print(target_lufs - 20*np.log10(np.max(np.abs(tmp))))\n",
    "        lufs = lufs_meter.integrated_loudness(\n",
    "            tmp)  # check if we got target_lufs\n",
    "        print(lufs)\n",
    "        # write wav of col space signals, for convenient listening files have equal lufs\n",
    "        wavfile.write(pathu+'left_singular_vector_'+str(cnt+1)+'.wav', fs, tmp)\n",
    "        cnt += 1\n",
    "        if cnt == Us.shape[1]:  # all col space sing vecs are processed\n",
    "            break\n",
    "plt.savefig(path+'plot_left_singular_vectors.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1a505f-55f1-4ff6-8dc7-cd8e09b3ebe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the polarity and level of the mixing weights\n",
    "# unity gain as weights in terms of the V space vectors (inner products)\n",
    "mixing_weight = Vh @ np.ones((s.size, 1))\n",
    "ui = np.arange(mixing_weight.size) + 1\n",
    "level = 10*np.log10(np.abs(mixing_weight)**2)  # dB\n",
    "level_pos = np.copy(level)\n",
    "level_pos[mixing_weight <= 0] = 0\n",
    "level_neg = np.copy(level)\n",
    "level_neg[mixing_weight > 0] = 0\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.stem(ui, level_pos, basefmt='white', linefmt='C0',\n",
    "         markerfmt='C0o', label='positiv polarity')\n",
    "plt.stem(ui, level_neg, basefmt='white', linefmt='C1',\n",
    "         markerfmt='C1o', label='negativ polarity')\n",
    "plt.xticks(ui)\n",
    "plt.legend()\n",
    "plt.xlabel('U column index')\n",
    "plt.ylabel('mixing weight in dB')\n",
    "plt.grid(True)\n",
    "plt.savefig(path+'mixing_weights.png')\n",
    "# print(mixing_weight)\n",
    "# print(20*np.log10(np.abs(mixing_weight)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3d24ed-5a43-4bbd-ba47-fc34510b3ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct A from SVD with rank 1...R\n",
    "# and mixdown to a mono signal\n",
    "# loudness normalization of mixdown\n",
    "for r in range(s.size):\n",
    "    # print(r)\n",
    "    s_reduced = np.copy(s)\n",
    "    s_reduced[r+1:] = 0\n",
    "    # print(s_reduced)\n",
    "    tmp = U @ np.diag(s_reduced) @ mixing_weight\n",
    "    lufs = lufs_meter.integrated_loudness(tmp)  # calc 1770 loudness\n",
    "    tmp *= 10**((target_lufs - lufs)/20)  # adapt to target_lufs\n",
    "    if np.max(np.abs(tmp)) > 1.:  # clipping might occur\n",
    "        print('!!! wav file clipping !!!, decrease target_lufs to:')\n",
    "        print(target_lufs - 20*np.log10(np.max(np.abs(tmp))))\n",
    "    lufs = lufs_meter.integrated_loudness(tmp)  # check if we got target_lufs\n",
    "    print(lufs)\n",
    "    # write wav of rank reduced mixdown, for convenient listening files have equal lufs\n",
    "    wavfile.write(patha+'rank_'+str(r+1)+'.wav', fs, tmp)\n",
    "# by that we can listen how the reduced SVD-factorization of matrix A\n",
    "# acting on equal mixing input vector (i.e. all A matrix columns get unity gain)\n",
    "# sounds like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96bff94-6ef3-40e3-8273-2aa218d2edb7",
   "metadata": {},
   "source": [
    "## Copyright\n",
    "\n",
    "- the notebooks are provided as [Open Educational Resources](https://en.wikipedia.org/wiki/Open_educational_resources)\n",
    "- feel free to use the notebooks for your own purposes\n",
    "- the text is licensed under [Creative Commons Attribution 4.0](https://creativecommons.org/licenses/by/4.0/)\n",
    "- the code of the IPython examples is licensed under under the [MIT license](https://opensource.org/licenses/MIT)\n",
    "- please attribute the work as follows: *Frank Schultz, Data Driven Audio Signal Processing - A Tutorial Featuring Computational Examples, University of Rostock* ideally with relevant file(s), github URL https://github.com/spatialaudio/data-driven-audio-signal-processing-exercise, commit number and/or version tag, year."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1743232f157dd0954c61aae30535e75a2972519a625c7e796bafe0cd9a07bf7e"
  },
  "kernelspec": {
   "display_name": "myddasp",
   "language": "python",
   "name": "myddasp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
