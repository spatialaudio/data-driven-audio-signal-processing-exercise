{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ff5888c",
   "metadata": {},
   "source": [
    "Sascha Spors,\n",
    "Professorship Signal Theory and Digital Signal Processing,\n",
    "Institute of Communications Engineering (INT),\n",
    "Faculty of Computer Science and Electrical Engineering (IEF),\n",
    "University of Rostock,\n",
    "Germany\n",
    "\n",
    "# Data Driven Audio Signal Processing - A Tutorial with Computational Examples\n",
    "\n",
    "Winter Semester 2023/24 (Master Course #24512)\n",
    "\n",
    "- lecture: https://github.com/spatialaudio/data-driven-audio-signal-processing-lecture\n",
    "- tutorial: https://github.com/spatialaudio/data-driven-audio-signal-processing-exercise\n",
    "\n",
    "Feel free to contact lecturer frank.schultz@uni-rostock.de"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a199b3df",
   "metadata": {},
   "source": [
    "# Binary logistic regression model with one sigmoid layer\n",
    "- training using gradient descent and forward/backward propagation\n",
    "- we follow the derivations and coding conventions from the brilliant course https://www.coursera.org/learn/neural-networks-deep-learning, cf. especially week 2\n",
    "- we compare **our implementation** against a model that is trained with **TensorFlow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a46046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "print(\n",
    "    \"TF version\",\n",
    "    tf.__version__,\n",
    ")\n",
    "\n",
    "tf.keras.backend.set_floatx(\"float64\")  # we use double precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf1c547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rng = np.random.RandomState(1)  # for debug\n",
    "rng = np.random.RandomState()\n",
    "\n",
    "verbose = 0  # plot training status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f8009a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sigmoid(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4236c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(y_true, y_pred):\n",
    "    # vectorized loss function\n",
    "    L = -(y_true * np.log(y_pred) + (1.0 - y_true) * np.log(1.0 - y_pred))\n",
    "    # cost function as average of all entries in L\n",
    "    J = np.mean(L)\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c795c19c-aa94-48b9-9385-390fd831a1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class_tf(y):\n",
    "    y[y[:, 0] < 0.5, :], y[y[:, 0] >= 0.5, :] = 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8388f542-910c-408f-9df7-b9ef4ed6f02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class_my(y):\n",
    "    y[:, y[0, :] < 0.5], y[:, y[0, :] >= 0.5] = 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4677582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred):\n",
    "    y_true_tmp = np.copy(y_true)\n",
    "    y_pred_tmp = np.copy(y_pred)\n",
    "    predict_class_my(y_pred_tmp)\n",
    "\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/math/confusion_matrix\n",
    "    # The matrix columns represent the prediction labels.\n",
    "    # The rows represent the real labels.\n",
    "    # real=0,pred=0    real=0,pred=1\n",
    "    # real=1,pred=0    real=1,pred=1\n",
    "    cm = np.zeros((2, 2), dtype=int)  # 2x2 in our example with two classes\n",
    "\n",
    "    # correct predictions:\n",
    "    # real=0,pred=0\n",
    "    cm[0, 0] = int(\n",
    "        np.sum(\n",
    "            np.logical_and(\n",
    "                np.logical_not(y_true_tmp), np.logical_not(y_pred_tmp)\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    # real=1,pred=1:\n",
    "    cm[1, 1] = int(np.sum(np.logical_and(y_true_tmp, y_pred_tmp)))\n",
    "\n",
    "    # false predictions:\n",
    "    # real=0,pred=1\n",
    "    cm[0, 1] = int(\n",
    "        np.sum(np.logical_and(np.logical_not(y_true_tmp), y_pred_tmp))\n",
    "    )\n",
    "\n",
    "    # real=1,pred=0\n",
    "    cm[1, 0] = int(\n",
    "        np.sum(np.logical_and(y_true_tmp, np.logical_not(y_pred_tmp)))\n",
    "    )\n",
    "\n",
    "    M_tmp = np.sum(cm)\n",
    "    print(M_tmp, y_true_tmp.shape)\n",
    "\n",
    "    cm_in_percent = cm / M_tmp * 100\n",
    "\n",
    "    # real=1,pred=1 related to all real=1\n",
    "    recall = cm[1, 1] / np.sum(cm[1, :])  # TPR\n",
    "    # real=1,pred=1 related to all pred=1\n",
    "    precision = cm[1, 1] / np.sum(cm[:, 1])  # PPV\n",
    "\n",
    "    # sum of diagonal entries (i.e. matrix trace, i.e. correct predictions)\n",
    "    # related to total\n",
    "    accuracy = np.sum(np.diag(cm)) / M_tmp\n",
    "\n",
    "    # balanced F-score, F1 score\n",
    "    F1_score = 2 / (1 / precision + 1 / recall)  # harmonic mean\n",
    "\n",
    "    return cm, cm_in_percent, precision, recall, F1_score, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b6db28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some toy data\n",
    "M = 100000  # number of samples per feature\n",
    "N = 2  # number of features (excluding bias)\n",
    "train_size = 0.8  # 80% of data are used for training\n",
    "\n",
    "X, Y = make_classification(\n",
    "    n_samples=M,\n",
    "    n_features=N,\n",
    "    n_informative=N,\n",
    "    n_redundant=0,\n",
    "    n_classes=2,\n",
    "    n_clusters_per_class=1,\n",
    "    class_sep=1,\n",
    "    flip_y=1e-2,\n",
    "    random_state=8,\n",
    ")\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, train_size=train_size, random_state=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a55e0d",
   "metadata": {},
   "source": [
    "### Prepare Model Training\n",
    "\n",
    "- get training data set for our implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c594e3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_train = X_train.shape[0]\n",
    "print(\"\\nM_train\", M_train)\n",
    "# our own implementation needs transposed data\n",
    "X_train_our = X_train.T\n",
    "Y_train_our = Y_train[None, :]\n",
    "print(\"X train dim\", X_train_our.shape, \"Y train dim\", Y_train_our.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3aedc53-87b0-4e3c-91a7-73be1df13b95",
   "metadata": {},
   "source": [
    "- prep for TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4f778d-786a-4146-a662-4bbafa8577e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train[:, None]  # newer TF needs  (x,1) instead of (x) arrays\n",
    "Y_test = Y_test[:, None]\n",
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b9c6e6",
   "metadata": {},
   "source": [
    "- set gradient descent hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109bc1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in practice we do hyper parameter tuning, cf. upcoming exercises\n",
    "step_size = 0.25\n",
    "steps = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158c8df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we init weights and bias with uniform PDF noise\n",
    "w_init = (rng.rand(N, 1) - 0.5) * 2.0\n",
    "b_init = (rng.rand(1, 1) - 0.5) * 2.0\n",
    "print(w_init.shape)\n",
    "print(b_init.shape)\n",
    "print([w_init, b_init[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c905cce",
   "metadata": {},
   "source": [
    "###  Model Training -> Own Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83d68c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up init model parameters\n",
    "w, b = w_init, b_init\n",
    "\n",
    "# batch gradient descent\n",
    "# take all training data per epoch\n",
    "# hence one epoch == one GD step to calc new gradient and new model parameters\n",
    "for step in range(steps):\n",
    "    # forward propagation = calc current prediction, i.e. model output\n",
    "    # using the current weights and the current bias:\n",
    "    Z = np.dot(w.T, X_train_our) + b  # forward step 1 = inner product + bias\n",
    "    A = my_sigmoid(Z)  # forward step 2 = apply activation function = y hat\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"epoch\",\n",
    "            step,\n",
    "            \"/\",\n",
    "            steps,\n",
    "            \", cost on training data\",\n",
    "            cost(Y_train_our, A),\n",
    "        )\n",
    "\n",
    "    # backward propagation, start at the model output and subsequently\n",
    "    # move backwards to model input\n",
    "    # vectorized implementation\n",
    "    # step 1: dL/da = d L / d yhat\n",
    "    da = -Y_train_our / A + (1 - Y_train_our) / (1 - A)\n",
    "    # step 2: (dL/da) * da/dz\n",
    "    dz = da * A * (1 - A)\n",
    "    # step 3a: dL/dw = (dL/da * da/dz) * dz/dw and\n",
    "    # note that inner product not only realizes the last multiplication of the\n",
    "    # back prop chain rule, but also sums up and averages to obtain the empirical risk\n",
    "    dw = np.dot(X_train_our, dz.T) / M_train\n",
    "    # step 3b: dL/db = dL/da * da/dz * dz/db, mean operation to obtain empirical risk\n",
    "    db = np.mean(dz * 1)\n",
    "\n",
    "    # GD update rule\n",
    "    w = w - step_size * dw\n",
    "    b = b - step_size * db\n",
    "\n",
    "# prediction after training finished:\n",
    "A = my_sigmoid(np.dot(w.T, X_train_our) + b)\n",
    "\n",
    "# get technical measures for the trained model on the training data set\n",
    "J_train = cost(Y_train_our, A)\n",
    "(\n",
    "    cm_train,\n",
    "    cm_train_percent,\n",
    "    precision_train,\n",
    "    recall_train,\n",
    "    F1_score_train,\n",
    "    accuracy_train,\n",
    ") = evaluate(Y_train_our, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d5e9b2",
   "metadata": {},
   "source": [
    "### Model Training -> Implementation Using Tensor Flow\n",
    "\n",
    "- set up the TF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f718ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = keras.initializers.RandomUniform(minval=0.0, maxval=1.0)\n",
    "\n",
    "optimizer = keras.optimizers.SGD(\n",
    "    learning_rate=step_size, momentum=0.0, nesterov=False\n",
    ")  # use_ema=False in 2.11.0\n",
    "\n",
    "loss = keras.losses.BinaryCrossentropy(from_logits=False, label_smoothing=0)\n",
    "\n",
    "metrics = [\n",
    "    keras.metrics.BinaryCrossentropy(),\n",
    "    keras.metrics.BinaryAccuracy(),\n",
    "    keras.metrics.Precision(),  # PPV (FP related)\n",
    "    keras.metrics.Recall(),  # TPR (FN related)\n",
    "]\n",
    "\n",
    "input = keras.Input(shape=(N,))\n",
    "\n",
    "output = keras.layers.Dense(\n",
    "    1, kernel_initializer=initializer, activation=\"sigmoid\"\n",
    ")(input)\n",
    "\n",
    "model = keras.Model(inputs=input, outputs=output)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe06fe6b",
   "metadata": {},
   "source": [
    "- optionally: we use **same init weights and bias** as in our implementation, set `if True:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b24371",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TF initial model parameters from keras.initializers\")\n",
    "print(model.get_weights())\n",
    "print(\"our initial model parameters\")\n",
    "print([w_init, b_init[0]])\n",
    "if True:\n",
    "    model.set_weights([w_init, b_init[0]])\n",
    "    print(\"are now TF initial model parameters\")\n",
    "    print(model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b21d86",
   "metadata": {},
   "source": [
    "- train/fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d239d6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, batch_size=M_train, epochs=steps, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81134fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"trained TF model parameters\")\n",
    "print(model.get_weights())\n",
    "print(\"trained model parameters from our implementation\")\n",
    "print([w, b[0]])\n",
    "if False:\n",
    "    model.set_weights([w, b[0]])\n",
    "    print(\"are now TF model parameters\")\n",
    "    print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff899ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction after training finished\n",
    "Y_train_pred_tf = model.predict(X_train)\n",
    "predict_class_tf(Y_train_pred_tf)\n",
    "\n",
    "print(Y_train_pred_tf.shape, Y_train.shape)\n",
    "\n",
    "# confusion matrix\n",
    "cm_train_tf = tf.math.confusion_matrix(\n",
    "    labels=np.squeeze(Y_train), predictions=np.squeeze(Y_train_pred_tf), num_classes=2\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# get technical measures for the trained model on the training data set\n",
    "results_train_tf = model.evaluate(\n",
    "    X_train, Y_train, batch_size=M_train, verbose=verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc8979a",
   "metadata": {},
   "source": [
    "### Performance Measures: Fitted Model on Training Data Set\n",
    "\n",
    "our implementation vs. TF model\n",
    "- cost, accuracy, precision = PPV (FP related), recall = TPR (FN related)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f05c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"our cost\", J_train)\n",
    "print(\"TF cost \", results_train_tf[0], \"\\n\")\n",
    "print(\"our accuray\", accuracy_train)\n",
    "print(\"TF accuracy\", results_train_tf[2], \"\\n\")\n",
    "print(\"our precision/PPV\", precision_train)\n",
    "print(\"TF precision/PPV\", results_train_tf[3], \"\\n\")\n",
    "print(\"our recall/TPR\", recall_train)\n",
    "print(\"TF recall/TPR\", results_train_tf[4], \"\\n\")\n",
    "print(\"our F1_score\", F1_score_train * 100.0, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8006bc3",
   "metadata": {},
   "source": [
    "- confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14faed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/math/confusion_matrix\n",
    "# The matrix columns represent the prediction labels.\n",
    "# The rows represent the real labels.\n",
    "print(\"confusion matrix:\\nreal0,pred0  real0,pred1\\nreal1,pred0  real1,pred1\")\n",
    "print(\"our confusion matrix (counts)\\n\", cm_train)\n",
    "print(\"TF confusion matrix (counts)\\n\", cm_train_tf)\n",
    "print(\"our confusion matrix in %\\n\", cm_train_percent)\n",
    "print(\"TF confusion matrix in %\\n\", cm_train_tf / M_train * 100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700d3cd5",
   "metadata": {},
   "source": [
    "- check model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2f7f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"our\\nweights w\", w.T, \"\\nbias b\", b, \"\\n\")\n",
    "print(\n",
    "    \"TF\\nweights w\",\n",
    "    model.get_weights()[0].T,\n",
    "    \"\\nbias b\",\n",
    "    model.get_weights()[1],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4013152",
   "metadata": {},
   "source": [
    "### Prepare Model Testing\n",
    "\n",
    "- get test data set for our implementation\n",
    "- **test data is not used for model training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfc90d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_test = X_test.shape[0]\n",
    "print(\"\\nm_test\", M_test)\n",
    "# our implementation needs transposed data\n",
    "X_test_our = X_test.T\n",
    "Y_test_our = Y_test.T\n",
    "print(\"X test dim\", X_test_our.shape, \"Y test dim\", Y_test_our.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9243acf",
   "metadata": {},
   "source": [
    "###  Model Testing -> Own Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cde6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do model prediction == forward propagation using test data\n",
    "A = my_sigmoid(np.dot(w.T, X_test_our) + b)  # Yhat\n",
    "J_test = cost(Y_test_our, A)\n",
    "(\n",
    "    cm_test,\n",
    "    cm_test_percent,\n",
    "    precision_test,\n",
    "    recall_test,\n",
    "    F1_score_test,\n",
    "    accuracy_test,\n",
    ") = evaluate(Y_test_our, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882a658d",
   "metadata": {},
   "source": [
    "### Model Testing -> Implementation Using Tensor Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27860801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "Y_test_pred_tf = model.predict(X_test)\n",
    "predict_class_tf(Y_test_pred_tf)\n",
    "\n",
    "# confusion matrix\n",
    "cm_test_tf = tf.math.confusion_matrix(\n",
    "    labels=np.squeeze(Y_test), predictions=np.squeeze(Y_test_pred_tf), num_classes=2\n",
    ")\n",
    "\n",
    "# get technical measures for the trained model on the training data set\n",
    "results_test_tf = model.evaluate(\n",
    "    X_test, Y_test, batch_size=M_test, verbose=verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06112f34",
   "metadata": {},
   "source": [
    "### Performance Measures: Fitted Model on Test Data Set\n",
    "\n",
    "our implementation vs. TF model\n",
    "- cost, accuracy, precision = PPV (FP related), recall = TPR (FN related)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843bdaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"our cost\", J_test)\n",
    "print(\"TF cost \", results_test_tf[0], \"\\n\")\n",
    "print(\"our accuray\", accuracy_test)\n",
    "print(\"TF accuracy\", results_test_tf[2], \"\\n\")\n",
    "print(\"our precision/PPV\", precision_test)\n",
    "print(\"TF precision/PPV\", results_test_tf[3], \"\\n\")\n",
    "print(\"our recall/TPR\", recall_test)\n",
    "print(\"TF recall/TPR\", results_test_tf[4], \"\\n\")\n",
    "print(\"our F1_score\", F1_score_test * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76396a3a",
   "metadata": {},
   "source": [
    "- confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc0fe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/math/confusion_matrix\n",
    "# The matrix columns represent the prediction labels.\n",
    "# The rows represent the real labels.\n",
    "print(\"confusion matrix:\\nreal0,pred0  real0,pred1\\nreal1,pred0  real1,pred1\")\n",
    "print(\"our confusion matrix (counts)\\n\", cm_test)\n",
    "print(\"TF confusion matrix (counts)\\n\", cm_test_tf)\n",
    "print(\"our confusion matrix in %\\n\", cm_test_percent)\n",
    "print(\"TF confusion matrix in %\\n\", cm_test_tf / M_test * 100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37d308d-9be7-4394-a7fd-d08a1feb279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6fbec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "if N == 2:  # 2D plot of data and classification line when having two features\n",
    "    f1, f2 = np.arange(-6, 6, 0.1), np.arange(-6, 6, 0.1)\n",
    "    xv, yv = np.meshgrid(f1, f2)\n",
    "    tmp = my_sigmoid(w[0] * xv + w[1] * yv + b)  # we use our model parameters\n",
    "    tmp[tmp < 0.5], tmp[tmp >= 0.5] = 0, 1\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(X_train[Y_train[:, 0] == 0, 0], X_train[Y_train[:, 0] == 0, 1], \"C0o\", ms=1)\n",
    "    plt.plot(X_train[Y_train[:, 0] == 1, 0], X_train[Y_train[:, 0] == 1, 1], \"C1o\", ms=1)\n",
    "    plt.contourf(f1, f2, tmp, cmap=\"RdBu_r\")\n",
    "    plt.axis(\"equal\")\n",
    "    plt.colorbar()\n",
    "    plt.title(\"training \" + str(X_train.shape))\n",
    "    plt.xlabel(\"feature 1\")\n",
    "    plt.ylabel(\"feature 2\")\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(X_test[Y_test[:, 0] == 0, 0], X_test[Y_test[:, 0] == 0, 1], \"C0o\", ms=1)\n",
    "    plt.plot(X_test[Y_test[:, 0] == 1, 0], X_test[Y_test[:, 0] == 1, 1], \"C1o\", ms=1)\n",
    "    plt.contourf(f1, f2, tmp, cmap=\"RdBu_r\")\n",
    "    plt.axis(\"equal\")\n",
    "    plt.colorbar()\n",
    "    plt.title(\"test \" + str(X_test.shape))\n",
    "    plt.xlabel(\"feature 1\")\n",
    "    plt.ylabel(\"feature 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651b1eff",
   "metadata": {},
   "source": [
    "## Copyright\n",
    "\n",
    "- the notebooks are provided as [Open Educational Resources](https://en.wikipedia.org/wiki/Open_educational_resources)\n",
    "- feel free to use the notebooks for your own purposes\n",
    "- the text is licensed under [Creative Commons Attribution 4.0](https://creativecommons.org/licenses/by/4.0/)\n",
    "- the code of the IPython examples is licensed under the [MIT license](https://opensource.org/licenses/MIT)\n",
    "- please attribute the work as follows: *Frank Schultz, Data Driven Audio Signal Processing - A Tutorial Featuring Computational Examples, University of Rostock* ideally with relevant file(s), github URL https://github.com/spatialaudio/data-driven-audio-signal-processing-exercise, commit number and/or version tag, year."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myddasp",
   "language": "python",
   "name": "myddasp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
