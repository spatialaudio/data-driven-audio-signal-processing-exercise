{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sascha Spors,\n",
    "Professorship Signal Theory and Digital Signal Processing,\n",
    "Institute of Communications Engineering (INT),\n",
    "Faculty of Computer Science and Electrical Engineering (IEF),\n",
    "University of Rostock,\n",
    "Germany\n",
    "\n",
    "# Data Driven Audio Signal Processing - A Tutorial with Computational Examples\n",
    "\n",
    "Master Course #24512\n",
    "\n",
    "- lecture: https://github.com/spatialaudio/data-driven-audio-signal-processing-lecture\n",
    "- tutorial: https://github.com/spatialaudio/data-driven-audio-signal-processing-exercise\n",
    "\n",
    "Feel free to contact lecturer frank.schultz@uni-rostock.de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Audio Features\n",
    "\n",
    "## Objectives\n",
    "\n",
    "There is a vast amount of audio features / measures that can be extracted from audio files and subsequently used for human inspection and/or machine learning (ML) applications. We want to learn some of them here and we want to humanly interprete them on some nice audio data. Once we got an impression from the information we can draw as humans, we can make faithful decisions on how and when to apply this for ML.\n",
    "\n",
    "We will deal with\n",
    "- Loudness and true peak measures\n",
    "- Sample Histogram\n",
    "- STFT power spectrum\n",
    "- Spectral Centroid\n",
    "- Periodogram\n",
    "\n",
    "## Special Python Packages\n",
    "- in this exercise we use the `pyloudnorm` package from https://github.com/csteinmetz1/pyloudnorm, we might install it by `pip install pyloudnorm` \n",
    "- in this exercise we also use `librosa` package (see https://librosa.org/doc/latest/index.html), we might install it by `pip install librosa`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Initial Python Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pyloudnorm as pyln\n",
    "import warnings\n",
    "from matplotlib.cm import get_cmap\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import resample, stft, welch\n",
    "from scipy.signal.windows import kaiser\n",
    "\n",
    "import librosa.display  # matplotlib dependencies?, therefore import afterwards\n",
    "\n",
    "CI_flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate some audio data, in case that audio_ex02 folder is empty\n",
    "if True:\n",
    "    fs = 44100\n",
    "    if CI_flag:\n",
    "        N = fs * 2\n",
    "    else:\n",
    "        N = fs * 30\n",
    "    k = np.arange(N)\n",
    "\n",
    "    fdes = 441 * 3\n",
    "    x = 0.5 * np.sin(2 * np.pi * fdes / fs * k)\n",
    "    x = np.tile(x, (2, 1)).T\n",
    "    print(x.shape)\n",
    "    wavfile.write(\"audio_ex02/sine.wav\", fs, x.astype(np.float32))\n",
    "\n",
    "    x = np.random.randn(N, 2)\n",
    "    x /= np.max(np.abs(x))\n",
    "    x *= 0.5\n",
    "    print(x.shape)\n",
    "    wavfile.write(\"audio_ex02/noise.wav\", fs, x.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_cmap(xmax, dbrange):\n",
    "    \"\"\"cmap for STFT 20log10(|X[t,f]|) in dB.\"\"\"\n",
    "    col_tick = np.linspace(xmax - dbrange, xmax, dbrange, endpoint=True)\n",
    "    cmap = get_cmap(\"magma\").copy()\n",
    "    cmap.set_over(\"C3\")\n",
    "    cmap.set_under(\"C7\")\n",
    "    norm = BoundaryNorm(col_tick, cmap.N)\n",
    "    return cmap, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")  # annoying scipy.io.wavfile.read warnings\n",
    "\n",
    "N_OS = 8  # oversample factor for true peak\n",
    "dbrange = 72  # colormap dB range for STFT surface plots\n",
    "\n",
    "ch = 1  # 0...left channel, 1...right channel for stereo file\n",
    "\n",
    "folder = \"audio_ex02/\"\n",
    "files = sorted(os.listdir(folder))  # get file names in this folder\n",
    "print(files)\n",
    "\n",
    "# for debug tests choose certain wav-files\n",
    "# files = [files[1]]\n",
    "# print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Load with Librosa vs. Scipy I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in files:\n",
    "    if i[-4:] == \".wav\":  # consider only wav files\n",
    "        # make sure to check defaults, they might be not convenient for us\n",
    "        xlib, fslib = librosa.load(\n",
    "            folder + i, mono=False, sr=None, dtype=\"double\"\n",
    "        )\n",
    "        fssci, xsci = wavfile.read(folder + i)\n",
    "\n",
    "        # we rather should use the shape (number of samples, number of channels)\n",
    "        xlib = xlib.T\n",
    "        print(\"audio load x librosa == scipy.io:\", np.allclose(xlib, xsci))\n",
    "        print(\"audio load fs librosa == scipy.io:\", np.allclose(fslib, fssci))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate BS.1170 Loudness, True Peak and Histogram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in files:\n",
    "    if i[-4:] == \".wav\":  # consider only wav files\n",
    "        fs, x = wavfile.read(folder + i)\n",
    "\n",
    "        # true peak in decibel true peak (dBTP)\n",
    "        xr = resample(x, N_OS * x.shape[0])\n",
    "        dbtp = 20 * np.log10(np.max(np.abs(xr)))\n",
    "\n",
    "        # normalize to desired dBTP\n",
    "        dbtp_des = 0.0\n",
    "        x *= 10 ** ((dbtp_des - dbtp) / 20)\n",
    "\n",
    "        # check dBTP\n",
    "        xr = resample(x, N_OS * x.shape[0])\n",
    "        dbtp = 20 * np.log10(np.max(np.abs(xr)))\n",
    "\n",
    "        # measure loudness in\n",
    "        # 'loudness units relative to full scale' (LUFS)\n",
    "        # according to https://www.itu.int/rec/R-REC-BS.1770\n",
    "        meter = pyln.Meter(fs)\n",
    "        lufs = meter.integrated_loudness(x)\n",
    "\n",
    "        msg = (\n",
    "            f\"{'file: ' + i:<30}\"\n",
    "            f\"{'dBTP: '} {dbtp:+4.2f} \\t\"\n",
    "            f\"{'LUFS: '} {lufs:+4.2f}\"\n",
    "        )\n",
    "        print(msg)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.hist(x, range=(-1, 1), bins=\"auto\", density=True)\n",
    "        plt.title(\n",
    "            f\"{i}\" f\"{', dBTP:'} {dbtp:+4.2f}\" f\"{', LUFS:'} {lufs:+4.2f}\"\n",
    "        )\n",
    "        plt.xlabel(\"sample value\")\n",
    "        plt.ylabel(\"density-like occurence\")\n",
    "        plt.savefig(folder + i[:-4] + \"_LUFS_hist.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate and Plot STFT Power Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CI_flag:\n",
    "    nperseg, nfft = 2**10, 2**10\n",
    "else:\n",
    "    nperseg, nfft = 2**14, 2**18\n",
    "\n",
    "for i in files:\n",
    "    if i[-4:] == \".wav\":  # consider only wav files\n",
    "        fs, x = wavfile.read(folder + i)\n",
    "\n",
    "        f, t, X = stft(\n",
    "            x[:, ch], fs, window=\"hamming\", nperseg=nperseg, nfft=nfft\n",
    "        )\n",
    "        Xmaxdb = 10 * np.log10(np.max(np.abs(X) ** 2))\n",
    "\n",
    "        cbticks = np.arange(Xmaxdb - dbrange, Xmaxdb + 6, 6)\n",
    "        cmap, norm = set_cmap(Xmaxdb, dbrange)\n",
    "        fig, ax = plt.subplots(figsize=(6, 5), nrows=1, ncols=1)\n",
    "        srf = ax.pcolormesh(\n",
    "            t, f, 10 * np.log10(np.abs(X) ** 2), cmap=cmap, norm=norm\n",
    "        )\n",
    "        cax = plt.colorbar(srf, cmap=cmap, norm=norm, ticks=cbticks)\n",
    "        ax.set_ylim(2e1, 2e4)\n",
    "        plt.yscale(\"log\")\n",
    "        ax.set_title(\"STFT Magnitude: \" + i)\n",
    "        ax.set_ylabel(\"f / Hz\")\n",
    "        ax.set_xlabel(\"t / s\")\n",
    "        cax.ax.set_xlabel(\"dB\")\n",
    "        plt.savefig(folder + i[:-4] + \"_STFT.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modified Periodogram\n",
    "\n",
    "We estimate the power spectral density.\n",
    "\n",
    "We use the Welch method with Kaiser-Bessel window (contrary to a Hann or a Hamming window, we can conveniently parametrize Kaiser-Bessel by `beta`).\n",
    "\n",
    "By using a window in the Welch method, we obtain a modified peridogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CI_flag:\n",
    "    nperseg, nfft = 2**10, 2**10\n",
    "else:\n",
    "    nperseg, nfft = 2**11, 2**18\n",
    "\n",
    "kaiser_beta = 5\n",
    "\n",
    "for i in files:\n",
    "    if i[-4:] == \".wav\":  # consider only wav files\n",
    "        fs, x = wavfile.read(folder + i)\n",
    "        f, Pxx_den = welch(\n",
    "            x[:, ch],\n",
    "            fs,\n",
    "            nperseg=nperseg,\n",
    "            nfft=nfft,\n",
    "            window=kaiser(nperseg, beta=kaiser_beta),\n",
    "        )\n",
    "        Pxxdb = 10 * np.log10(Pxx_den)\n",
    "        Pxxdbmax = np.max(Pxxdb)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(6, 4), nrows=1, ncols=1)\n",
    "        plt.semilogx(f, Pxxdb)\n",
    "        plt.ylim(Pxxdbmax - dbrange + 6, Pxxdbmax + 6)\n",
    "        plt.xlim(2e1, 2e4)\n",
    "        plt.xlabel(\"frequency in Hz\")\n",
    "        plt.ylabel(\"Kaiser-Bessel Windowed Welch Estimate of PSD in dB\")\n",
    "        plt.title(i)\n",
    "        plt.grid(True)\n",
    "        plt.savefig(folder + i[:-4] + \"_PSD.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral Centroid Using Librosa\n",
    "\n",
    "We should **carefully check** if the **defaults** of functions suit our needs!!!\n",
    "\n",
    "For example, by default all loaded audio is resampled to 22050 Hz and mixed down to mono. We might not find this very useful.\n",
    "\n",
    "So make sure, that correct sampling frequency is handled and given to all the functions that rely on it, otherwise very strange results can occur!\n",
    "\n",
    "STFT has many parameters, so we might also check these in detail. In the example below we can live with the defaults, just changing to the Hamming window.\n",
    "\n",
    "**Task@Home**: How to set up the STFT here so that we get precisely the same output as above, where we used `scipy.signal.stft` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"librosa version:\", librosa.__version__)\n",
    "# https://librosa.org/doc/latest/generated/librosa.feature.spectral_centroid.html?highlight=spectral%20centroid#librosa.feature.spectral_centroid\n",
    "\n",
    "# due to used librosa.amplitude_to_db(S, ref=np.max) normalization to 0 dB\n",
    "Xmaxdb = 0\n",
    "cbticks = np.arange(Xmaxdb - dbrange, Xmaxdb + 6, 6)\n",
    "cmap, norm = set_cmap(Xmaxdb, dbrange)\n",
    "\n",
    "for i in files:\n",
    "    if i[-4:] == \".wav\":  # consider only wav files\n",
    "        x, sr = librosa.load(folder + i, mono=False, sr=None, dtype=\"double\")\n",
    "        x = x.T\n",
    "        y = x[:, ch]\n",
    "\n",
    "        cent = librosa.feature.spectral_centroid(y=y, sr=sr, window=\"hamming\")\n",
    "        t_cent = librosa.times_like(cent, sr=sr)\n",
    "        S, _ = librosa.magphase(librosa.stft(y=y, window=\"hamming\"))\n",
    "        fig, ax = plt.subplots(figsize=(6, 5), nrows=1, ncols=1)\n",
    "        srf = librosa.display.specshow(\n",
    "            librosa.amplitude_to_db(S, ref=np.max),\n",
    "            sr=sr,\n",
    "            y_axis=\"log\",\n",
    "            x_axis=\"time\",\n",
    "            ax=ax,\n",
    "            cmap=cmap,\n",
    "            norm=norm,\n",
    "        )\n",
    "        ax.plot(t_cent, cent.T, label=\"spectral centroid\", color=\"white\")\n",
    "        cax = plt.colorbar(srf, cmap=cmap, norm=norm, ticks=cbticks)\n",
    "        ax.legend(loc=\"upper right\")\n",
    "        ax.set(\n",
    "            title=\"log power spectrogram: \" + i, xlabel=\"t / s\", ylabel=\"f / Hz\"\n",
    "        )\n",
    "        cax.ax.set_xlabel(\"dB\")\n",
    "        plt.savefig(folder + i[:-4] + \"_SpectralCentroid.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral Centroid Manually on DFT Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs, x = wavfile.read(folder + \"noise.wav\")\n",
    "x = x[:, ch]\n",
    "nsig = x.shape[0]\n",
    "nfft = int(\n",
    "    2 ** np.ceil(np.log(nsig) / np.log(2))\n",
    ")  # ensure power of two and even\n",
    "X = np.fft.fft(x, n=nfft)\n",
    "\n",
    "df = fs / nfft  # DFT frequency resolution\n",
    "k = np.arange(nfft // 2 + 1)  # DFT frequency index vector for base band\n",
    "f = k * df  # frequency vector from 0 Hz to fs/2\n",
    "Xonesided = X[0 : nfft // 2 + 1]  # DFT spectrum from 0 Hz to fs/2\n",
    "\n",
    "# calc spectral centroid\n",
    "moment = 1\n",
    "norm = np.sum(np.abs(Xonesided) ** moment)\n",
    "spectral_centroid_k = np.inner(np.abs(Xonesided) ** moment, k) / norm\n",
    "spectral_centroid_f = np.inner(np.abs(Xonesided) ** moment, f) / norm\n",
    "\n",
    "print(\"spectral centroid is at DFT bin: \", spectral_centroid_k)\n",
    "print(\"spectral centroid is at frequency: \", spectral_centroid_f, \"Hz\")\n",
    "print(np.isclose(spectral_centroid_k * df, spectral_centroid_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copyright\n",
    "\n",
    "- the notebooks are provided as [Open Educational Resources](https://en.wikipedia.org/wiki/Open_educational_resources)\n",
    "- the text is licensed under [Creative Commons Attribution 4.0](https://creativecommons.org/licenses/by/4.0/)\n",
    "- the code of the IPython examples is licensed under the [MIT license](https://opensource.org/licenses/MIT)\n",
    "- feel free to use the notebooks for your own purposes\n",
    "- please attribute the work as follows: *Frank Schultz, Data Driven Audio Signal Processing - A Tutorial Featuring Computational Examples, University of Rostock* ideally with relevant file(s), github URL https://github.com/spatialaudio/data-driven-audio-signal-processing-exercise, commit number and/or version tag, year."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1743232f157dd0954c61aae30535e75a2972519a625c7e796bafe0cd9a07bf7e"
  },
  "kernelspec": {
   "display_name": "myddasp",
   "language": "python",
   "name": "myddasp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
