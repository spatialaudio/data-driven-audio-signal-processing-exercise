{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sascha Spors,\n",
    "Professorship Signal Theory and Digital Signal Processing,\n",
    "Institute of Communications Engineering (INT),\n",
    "Faculty of Computer Science and Electrical Engineering (IEF),\n",
    "University of Rostock,\n",
    "Germany\n",
    "\n",
    "# Data Driven Audio Signal Processing - A Tutorial with Computational Examples\n",
    "\n",
    "Winter Semester 2022/23 (Master Course #24512)\n",
    "\n",
    "- lecture: https://github.com/spatialaudio/data-driven-audio-signal-processing-lecture\n",
    "- tutorial: https://github.com/spatialaudio/data-driven-audio-signal-processing-exercise\n",
    "\n",
    "Feel free to contact lecturer frank.schultz@uni-rostock.de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Syllabus 2022/23\n",
    "\n",
    "TBD: we might change the sequence of the 2021/22 material (see below), certainly we will add new improved stuff, improve didactics and so on...\n",
    "\n",
    "\n",
    "## Exercise : Motivation / Introducing a Toy Example for SVD/Regression\n",
    "- [Introduction to the Course](exercise01.ipynb)\n",
    "\n",
    "\n",
    "## Exercise : Singular Value Decomposition (SVD) / 4 Subspaces\n",
    "\n",
    "- [SVD and 4 Subspaces](exercise04_svd.ipynb)\n",
    "- [SVD and 4 Subspaces, above example as Matlab script](svd_four_subspaces.m) \n",
    "\n",
    "\n",
    "## Exercise: Left Inverse / Linear Regression with Ordinary Least Squares (OLS)\n",
    "- [SVD and Left Inverse](exercise04_leftinv.ipynb)\n",
    "- [SVD and Right Inverse](exercise04_rightinv.ipynb)\n",
    "- [Linear Regression with OLS](ols.ipynb)\n",
    "\n",
    "\n",
    "## TBD\n",
    "- [Audio Signal Fundamentals](audio_introduction.ipynb)\n",
    "- [Bias-Variance Trade-Off vs. Model Complexity](bias_variance_linear_regression.ipynb)\n",
    "- [Bias-Variance Trade-Off vs. Regularization](bias_variance_ridge_regression.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textbook Recommendations\n",
    "\n",
    "- Gilbert **Strang**: *Linear Algebra and Learning from Data*, Wellesley, 2019, consider to buy your own copy of this brilliant book\n",
    "- Gareth **James**, Daniela Witten, Trevor Hastie, Rob Tibshirani: *An Introduction to Statistical Learning* with Applications in R, Springer, 2nd ed., 2021, [free pdf e-book](https://www.statlearning.com/)\n",
    "- Trevor **Hastie**, Robert Tibshirani, Jerome Friedman: *The Elements of  Statistical Learning: Data Mining, Inference, and Prediction*, Springer, 2nd ed., 2009, [free pdf e-book](https://hastie.su.domains/ElemStatLearn/)\n",
    "- Sergios **Theodoridis**: *Machine Learning*, Academic Press, 2nd ed., 2020, check your university library service for free pdf e-book\n",
    "- Kevin P. **Murphy**: *Probabilistic Machine Learning: An Introduction*, MIT Press, 1st. ed. [open source book and current draft as free pdf](https://probml.github.io/pml-book/book1.html)\n",
    "- Marc Peter **Deisenroth**, A. Aldo Faisal, Cheng Soon Ong: *Mathemathics for Machine Learning*, Cambridge University Press, 2020, [free pdf e-book](https://mml-book.github.io/)\n",
    "- Steven L. **Brunton**, J. Nathan Kutz: *Data Driven Science & Engineering - Machine Learning, Dynamical Systems, and Control*, Cambridge University Press, 2020, [free pdf of draft](http://www.databookuw.com/databook.pdf), see also the [video lectures](http://www.databookuw.com/) and [Python tutorials](https://github.com/dylewsky/Data_Driven_Science_Python_Demos)\n",
    "- Aurélien **Géron**: *Hands-on machine learning with Scikit-Learn, Keras and TensorFlow*. O’Reilly, 2nd ed., 2019, [Python tutorials](https://github.com/ageron/handson-ml2)\n",
    "\n",
    "ML deals with stuff that is actually known for decades (at least the linear modeling part of it), so if we are really serious about to learn ML deeply, we should think over concepts on statistical signal processing, maximum-likelihood, Bayesian vs. frequentist statistics, generalized linear models, hierarchical models...for that we could check these books\n",
    "- L. Fahrmeir, A. Hamerle, and G. Tutz, Multivariate statistische Verfahren, 2nd ed. de Gruyter, 1996.\n",
    "- L. Fahrmeir, T. Kneib, S. Lang, and B. D. Marx, Regression, 2nd ed. Springer, 2021.\n",
    "- A. J. Dobson and A. G. Barnett, An Introduction to Generalized Linear Models, 4th ed. CRC Press, 2018.\n",
    "- H. Madsen, P. Thyregod, Introduction to General and Generalized Linear Models, CRC Press, 2011.\n",
    "- A. Agresti, Foundations of Linear and Generalized Models, Wiley, 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Course Ware Recommendations\n",
    "\n",
    "- Online Course by Andrew **Ng** et al. at https://www.coursera.org/ and https://www.deeplearning.ai/\n",
    "- Online Course by Gilbert **Strang** et al. at https://ocw.mit.edu/courses/mathematics/18-065-matrix-methods-in-data-analysis-signal-processing-and-machine-learning-spring-2018/\n",
    "- Online Course/Material by Aurélien **Géron** https://github.com/ageron\n",
    "- Online Course by Meinard **Müller** https://www.audiolabs-erlangen.de/resources/MIR/FMP/B/B_GetStarted.html (focus on music information retrieval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Syllabus 2021/22\n",
    "\n",
    "## Exercise 1: Introduction\n",
    "[Introduction](exercise01.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Audio Features I (Segmentation, STFT, Spectrogram, Periodogram)\n",
    "\n",
    "[Audio Features I](exercise02.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Audio Features II (Segmentation, RMS/(True)Peak/Crest Factor, R128 loudness)\n",
    "\n",
    "[Audio Features II](exercise03.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: SVD / 4 Subspaces / Left Inverse\n",
    "\n",
    "- [SVD and 4 Subspaces](exercise04_svd.ipynb)\n",
    "- [SVD and Left Inverse](exercise04_leftinv.ipynb)\n",
    "- [SVD and Right Inverse](exercise04_rightinv.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Column Space Singular Vectors of a Multitrack Audio Matrix \n",
    "\n",
    "- [exercise05.ipynb](exercise05.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: Principal Component Analysis (PCA)\n",
    "\n",
    "- Matlab code:\n",
    "    - [exercise06_pca_2D.m](exercise06_pca_2D.m)\n",
    "    - [exercise06_pca_3D.m](exercise06_pca_3D.m)\n",
    "- Python notebooks TBD\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7: QR, SVD, Linear Regression vs. SVD Regression\n",
    "\n",
    "- [exercise07_QR.ipynb](exercise07_QR.ipynb)\n",
    "- [exercise07_left_inverse_SVD_QR.ipynb](exercise07_left_inverse_SVD_QR.ipynb)\n",
    "- [exercise07_linear_regression_LS_vs_SVD.ipynb](exercise07_linear_regression_LS_vs_SVD.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8: Ridge Regression / Bias vs. Variance\n",
    "\n",
    "- [exercise08_ridge_regression.ipynb](exercise08_ridge_regression.ipynb)\n",
    "- [exercise08_bias_variance.ipynb](exercise08_bias_variance.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9: Gradient Descent (Steepest Descent)\n",
    "\n",
    "- [exercise09_gradient_descent.m](exercise09_gradient_descent.m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 10: Perceptron / Neural Networks\n",
    "\n",
    "- The XOR mapping is a popular example to motivate non-linearities in models, as linear regression cannot solve this simple problem in [exercise10_xor_example.m](exercise10_xor_example.m)\n",
    "- Our own implementation of simple **0/1 classification** using only **one layer** with **sigmoid activation** function [exercise10_binary_logistic_regression.py](exercise10_binary_logistic_regression.py)\n",
    "\n",
    "We should not miss these brilliant resources to start with neural networks\n",
    "- [https://pythonalgos.com/create-a-neural-network-from-scratch-in-python-3/](https://pythonalgos.com/create-a-neural-network-from-scratch-in-python-3/)\n",
    "- [https://playground.tensorflow.org](https://playground.tensorflow.org)\n",
    "- https://www.tensorflow.org/tutorials/keras/overfit_and_underfit (and the other tutorials found there)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 11: Binary Classification\n",
    "\n",
    "- With [exercise11_binary_logistic_regression_tf.py](exercise11_binary_logistic_regression_tf.py) we **compare our** above implementation [exercise10_binary_logistic_regression.py](exercise10_binary_logistic_regression.py) **against a TF model**\n",
    "- Next, we create more complex models in [exercise11_binary_logistic_regression_tf_with_hidden_layers.py](exercise11_binary_logistic_regression_tf_with_hidden_layers.py) using **hidden layers**, but still with **manually tuned hyper parameters**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 12: Multiclass Classification\n",
    "\n",
    "- With [exercise12_MulticlassClassification_CategoricalCrossentropy.ipynb](exercise12_MulticlassClassification_CategoricalCrossentropy.ipynb) we expand the example [exercise11_binary_logistic_regression_tf_with_hidden_layers.py](exercise11_binary_logistic_regression_tf_with_hidden_layers.py) towards **classification of more than two classes** using **softmax activation** function in the output layer\n",
    "\n",
    "- With [exercise12_HyperParameterTuning.ipynb](exercise12_HyperParameterTuning.ipynb) we introduce\n",
    "    - data split into train, validate, test data sets\n",
    "    - hyper parameter tuning  \n",
    "    - one hot encoding\n",
    "    - training of best model with re-set weights using train / val data set\n",
    "    - final prediction on unseen test data set compared to predictions on train / val data sets\n",
    "    - confusion matrix and visualization of predictions\n",
    "    \n",
    "- Finally we apply all this to a music genre classification application in [exercise12_MusicGenreClassification.ipynb](exercise12_MusicGenreClassification.ipynb)\n",
    "    - feature design (loudness, crest, peak, rms, spectral weight)\n",
    "    - feature inspection / avoiding NaNs\n",
    "    - feature normalization\n",
    "    - balancing data set wrt class occurence\n",
    "    \n",
    "We could move on with dropout layers, regularization..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 13: CNN\n",
    "\n",
    "TBD\n",
    "\n",
    "[exercise13_CNN.py](exercise13_CNN.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autorship\n",
    "- the notebooks are provided as [Open Educational Resources](https://en.wikipedia.org/wiki/Open_educational_resources)\n",
    "- current main authors\n",
    "    - University of Rostock\n",
    "        - [Frank Schultz](https://orcid.org/0000-0002-3010-0294)\n",
    "        - [Sascha Spors](https://orcid.org/0000-0001-7225-9992)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencing\n",
    "- the notebooks are provided as [Open Educational Resources](https://en.wikipedia.org/wiki/Open_educational_resources)\n",
    "- please cite this open educational resource (OER) project as *Frank Schultz, Data Driven Audio Signal Processing - A Tutorial Featuring Computational Examples, University of Rostock* ideally with relevant ``file(s), github URL, commit number and/or version tag, year``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License\n",
    "- Creative Commons Attribution 4.0 International License ([CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)) for text / graphics\n",
    "- [MIT license](https://opensource.org/licenses/MIT) for software / code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myddasp",
   "language": "python",
   "name": "myddasp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
